{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e84cfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5aef0cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_csv(\"E:/Leeds University/Dissertation/desdata.csv\", delim_whitespace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62c16b20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Compound', 'G_sol', 'DeltaG_sol', 'volume', 'sol_dip', 'O_charges',\n",
       "       'C_charges', 'Most_neg', 'Most_pos', 'Het_charges', 'MW', 'SASA',\n",
       "       'LogS', 'Lsolu_Hsolv', 'Lsolv_Hsolu'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4959e52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[:, df.columns != 'Compound']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c050b23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split into features and target (Price)\n",
    "X = df.drop('LogS', axis = 1)\n",
    "y = df['LogS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd607289",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "08490276",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_xtrain = read_csv(\"E:/Leeds University/Dissertation/ann_xtrain.csv\", delim_whitespace=False)\n",
    "ann_xtest = read_csv(\"E:/Leeds University/Dissertation/ann_xtest.csv\", delim_whitespace=False)\n",
    "ann_ytrain = read_csv(\"E:/Leeds University/Dissertation/ann_ytrain.csv\", delim_whitespace=False)\n",
    "ann_ytest = read_csv(\"E:/Leeds University/Dissertation/ann_ytest.csv\", delim_whitespace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4022e90c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scale data, otherwise model will fail.\n",
    "#Standardize features by removing the mean and scaling to unit variance\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()\n",
    "scaler.fit(ann_xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "10970afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = scaler.transform(ann_xtrain)\n",
    "X_test_scaled = scaler.transform(ann_xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "500e9fdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LogS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-4.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-4.230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-5.510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-4.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-3.494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>-3.730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>-4.360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>-3.813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>-5.680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>-1.460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>268 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      LogS\n",
       "0   -4.100\n",
       "1   -4.230\n",
       "2   -5.510\n",
       "3   -4.001\n",
       "4   -3.494\n",
       "..     ...\n",
       "263 -3.730\n",
       "264 -4.360\n",
       "265 -3.813\n",
       "266 -5.680\n",
       "267 -1.460\n",
       "\n",
       "[268 rows x 1 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann_ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "24b72a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 128)               1792      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,113\n",
      "Trainable params: 10,113\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# define the model\n",
    "#Experiment with deeper and wider networks\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=13, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "#Output layer\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mae'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "206609d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "16/16 [==============================] - 1s 14ms/step - loss: 10.2245 - mae: 2.5869 - val_loss: 6.2698 - val_mae: 1.9309\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3.7845 - mae: 1.5788 - val_loss: 2.6435 - val_mae: 1.2883\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 2.3346 - mae: 1.1687 - val_loss: 1.9561 - val_mae: 1.0670\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.8414 - mae: 1.0572 - val_loss: 1.7799 - val_mae: 1.0304\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.6191 - mae: 0.9707 - val_loss: 1.6034 - val_mae: 0.9805\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.4696 - mae: 0.9154 - val_loss: 1.4832 - val_mae: 0.9417\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.3415 - mae: 0.8735 - val_loss: 1.4504 - val_mae: 0.9341\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.2572 - mae: 0.8458 - val_loss: 1.4102 - val_mae: 0.9255\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.2108 - mae: 0.8191 - val_loss: 1.4249 - val_mae: 0.9181\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.1339 - mae: 0.7929 - val_loss: 1.3525 - val_mae: 0.8969\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.0833 - mae: 0.7679 - val_loss: 1.3271 - val_mae: 0.8839\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.0500 - mae: 0.7613 - val_loss: 1.2970 - val_mae: 0.8725\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.0189 - mae: 0.7440 - val_loss: 1.2867 - val_mae: 0.8652\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.9796 - mae: 0.7256 - val_loss: 1.2901 - val_mae: 0.8620\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.9507 - mae: 0.7236 - val_loss: 1.2512 - val_mae: 0.8455\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.9246 - mae: 0.7066 - val_loss: 1.2737 - val_mae: 0.8527\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.8882 - mae: 0.6945 - val_loss: 1.2336 - val_mae: 0.8356\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.8775 - mae: 0.6899 - val_loss: 1.2282 - val_mae: 0.8288\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.8426 - mae: 0.6685 - val_loss: 1.2237 - val_mae: 0.8261\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.8186 - mae: 0.6697 - val_loss: 1.2006 - val_mae: 0.8157\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.8043 - mae: 0.6544 - val_loss: 1.2211 - val_mae: 0.8212\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7803 - mae: 0.6508 - val_loss: 1.1912 - val_mae: 0.8090\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7586 - mae: 0.6405 - val_loss: 1.2120 - val_mae: 0.8111\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7482 - mae: 0.6299 - val_loss: 1.2143 - val_mae: 0.8263\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7436 - mae: 0.6420 - val_loss: 1.1716 - val_mae: 0.7962\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7092 - mae: 0.6216 - val_loss: 1.1767 - val_mae: 0.7972\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6778 - mae: 0.6006 - val_loss: 1.1634 - val_mae: 0.7997\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6757 - mae: 0.6076 - val_loss: 1.1440 - val_mae: 0.7921\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6715 - mae: 0.6044 - val_loss: 1.1708 - val_mae: 0.7847\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6488 - mae: 0.6018 - val_loss: 1.1214 - val_mae: 0.7768\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6312 - mae: 0.5797 - val_loss: 1.1880 - val_mae: 0.7939\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6303 - mae: 0.5821 - val_loss: 1.1267 - val_mae: 0.7926\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6110 - mae: 0.5749 - val_loss: 1.1617 - val_mae: 0.7900\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5835 - mae: 0.5647 - val_loss: 1.1096 - val_mae: 0.7787\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5693 - mae: 0.5511 - val_loss: 1.1115 - val_mae: 0.7805\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5700 - mae: 0.5539 - val_loss: 1.1256 - val_mae: 0.7775\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5654 - mae: 0.5534 - val_loss: 1.0879 - val_mae: 0.7662\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5652 - mae: 0.5474 - val_loss: 1.0972 - val_mae: 0.7802\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5322 - mae: 0.5407 - val_loss: 1.0821 - val_mae: 0.7649\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5333 - mae: 0.5377 - val_loss: 1.1099 - val_mae: 0.7734\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5151 - mae: 0.5295 - val_loss: 1.0997 - val_mae: 0.7742\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5050 - mae: 0.5283 - val_loss: 1.0970 - val_mae: 0.7630\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.4890 - mae: 0.5190 - val_loss: 1.0599 - val_mae: 0.7580\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4813 - mae: 0.5145 - val_loss: 1.1118 - val_mae: 0.7710\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4702 - mae: 0.5074 - val_loss: 1.0602 - val_mae: 0.7592\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4638 - mae: 0.5002 - val_loss: 1.0431 - val_mae: 0.7527\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.4497 - mae: 0.4932 - val_loss: 1.0336 - val_mae: 0.7456\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.4422 - mae: 0.4889 - val_loss: 1.0089 - val_mae: 0.7363\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.4552 - mae: 0.4950 - val_loss: 1.1088 - val_mae: 0.7805\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.4617 - mae: 0.4991 - val_loss: 1.0205 - val_mae: 0.7516\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.4190 - mae: 0.4799 - val_loss: 1.0400 - val_mae: 0.7483\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.4135 - mae: 0.4817 - val_loss: 1.0732 - val_mae: 0.7658\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4242 - mae: 0.4866 - val_loss: 1.0722 - val_mae: 0.7565\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3894 - mae: 0.4645 - val_loss: 1.0323 - val_mae: 0.7553\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3938 - mae: 0.4654 - val_loss: 0.9981 - val_mae: 0.7394\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3854 - mae: 0.4615 - val_loss: 1.0257 - val_mae: 0.7436\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3769 - mae: 0.4542 - val_loss: 1.0300 - val_mae: 0.7426\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3815 - mae: 0.4563 - val_loss: 1.0516 - val_mae: 0.7550\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3645 - mae: 0.4546 - val_loss: 0.9967 - val_mae: 0.7290\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3550 - mae: 0.4449 - val_loss: 1.0194 - val_mae: 0.7536\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3448 - mae: 0.4378 - val_loss: 0.9908 - val_mae: 0.7310\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3372 - mae: 0.4339 - val_loss: 0.9950 - val_mae: 0.7367\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3319 - mae: 0.4314 - val_loss: 0.9779 - val_mae: 0.7269\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3414 - mae: 0.4397 - val_loss: 1.0204 - val_mae: 0.7309\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3436 - mae: 0.4369 - val_loss: 1.0237 - val_mae: 0.7328\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3206 - mae: 0.4185 - val_loss: 0.9788 - val_mae: 0.7193\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3110 - mae: 0.4169 - val_loss: 1.0206 - val_mae: 0.7294\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3122 - mae: 0.4252 - val_loss: 0.9867 - val_mae: 0.7117\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2976 - mae: 0.4088 - val_loss: 0.9851 - val_mae: 0.7202\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2917 - mae: 0.4038 - val_loss: 0.9722 - val_mae: 0.7120\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2888 - mae: 0.4030 - val_loss: 0.9926 - val_mae: 0.7162\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2848 - mae: 0.3990 - val_loss: 1.0644 - val_mae: 0.7365\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2862 - mae: 0.4012 - val_loss: 1.1012 - val_mae: 0.7755\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2992 - mae: 0.4096 - val_loss: 0.9989 - val_mae: 0.7192\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2800 - mae: 0.4022 - val_loss: 0.9917 - val_mae: 0.7152\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2607 - mae: 0.3859 - val_loss: 0.9352 - val_mae: 0.6960\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2600 - mae: 0.3819 - val_loss: 1.0020 - val_mae: 0.7213\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2592 - mae: 0.3834 - val_loss: 0.9774 - val_mae: 0.7132\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2564 - mae: 0.3847 - val_loss: 0.9173 - val_mae: 0.6815\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2529 - mae: 0.3820 - val_loss: 1.0065 - val_mae: 0.7349\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2479 - mae: 0.3799 - val_loss: 0.9981 - val_mae: 0.7264\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2593 - mae: 0.3756 - val_loss: 1.0026 - val_mae: 0.7432\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2639 - mae: 0.3922 - val_loss: 0.9543 - val_mae: 0.7063\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2430 - mae: 0.3743 - val_loss: 0.9580 - val_mae: 0.7006\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2551 - mae: 0.3821 - val_loss: 1.0087 - val_mae: 0.7078\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2318 - mae: 0.3660 - val_loss: 1.0113 - val_mae: 0.7255\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2290 - mae: 0.3686 - val_loss: 0.9651 - val_mae: 0.7033\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2098 - mae: 0.3429 - val_loss: 1.0140 - val_mae: 0.7278\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2182 - mae: 0.3531 - val_loss: 0.9578 - val_mae: 0.7062\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2122 - mae: 0.3460 - val_loss: 0.9954 - val_mae: 0.7013\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2462 - mae: 0.3634 - val_loss: 0.9926 - val_mae: 0.7044\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2090 - mae: 0.3455 - val_loss: 0.9685 - val_mae: 0.7009\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1968 - mae: 0.3302 - val_loss: 0.9797 - val_mae: 0.6957\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1928 - mae: 0.3259 - val_loss: 0.9886 - val_mae: 0.7137\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1919 - mae: 0.3291 - val_loss: 0.9906 - val_mae: 0.7252\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1913 - mae: 0.3290 - val_loss: 0.9697 - val_mae: 0.6845\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1898 - mae: 0.3290 - val_loss: 0.9856 - val_mae: 0.7128\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1948 - mae: 0.3395 - val_loss: 0.9952 - val_mae: 0.7000\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2026 - mae: 0.3411 - val_loss: 0.9235 - val_mae: 0.6702\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2068 - mae: 0.3544 - val_loss: 1.0033 - val_mae: 0.7247\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_scaled, ann_ytrain, validation_split=0.2, epochs =100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5d11c4fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "#plot the training and validation accuracy and loss at each epoch\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'y', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3016a70d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted values are:  [ -2.92077905  -3.66828076  -5.23971217  -3.15884715  -3.16491307\n",
      "  -4.4466909   -2.82857242  -2.34594697  -3.76307919  -4.07854425\n",
      "  -3.01488488  -1.60055565  -0.69878049  -0.29589063  -2.65751968\n",
      "  -4.43457486  -2.431158    -2.32770961   0.17601953  -0.3419728\n",
      "  -2.91333984  -6.11093524  -6.78434512  -3.84512786  -0.68547613\n",
      "  -4.84210637  -3.40458779  -1.98405517  -6.77506748  -3.03588964\n",
      "  -2.14526755  -2.98588001  -3.82050049  -0.56556705  -0.44415621\n",
      "  -0.54328304  -3.94794057  -5.25062457  -2.76682529  -3.32023714\n",
      "  -2.86338241  -2.26325104  -1.81823806  -8.49030548  -2.78033\n",
      "  -3.5495207   -3.34538857  -1.94574139  -2.80708241  -3.15653275\n",
      "  -4.984813    -2.34482462 -10.9845985   -0.5837452   -3.35496628\n",
      "   0.08622565   0.7298612   -4.85439484  -8.08068238  -4.60447619\n",
      "  -0.19439875  -3.61543612  -1.48922091  -4.94442465   0.11840123\n",
      "  -7.368361    -3.03242156  -0.57564734  -5.57898177  -0.79874906\n",
      "  -5.66097939  -6.61929693  -8.02293156  -4.21743126  -2.99605131\n",
      "  -3.34561194  -4.84470083  -0.46445673  -8.2326232   -0.86509946\n",
      "   0.66088685  -5.24553238  -0.37421031  -2.86767792   0.2199205\n",
      "  -0.30627747  -3.21097851  -5.10771835  -0.28119641  -0.45568934\n",
      "  -2.65404778  -4.56676388  -1.09383145  -4.88079501  -4.68075394\n",
      "  -2.96800753  -7.25880924  -0.71678417  -4.92114558  -2.81097271\n",
      "  -5.09125155  -4.93584229  -0.49807765   0.42299443   0.39986632\n",
      "  -2.01995154  -4.891774    -2.87191854  -2.13839608   0.04206339\n",
      "  -5.28284609  -0.16438199  -1.34703566  -4.00336136  -1.82360215\n",
      "  -0.1947875   -1.62744008  -4.06670188  -5.37374103   0.01116125\n",
      "  -5.61793441  -3.80204076  -3.87866134  -1.20150398  -2.62942785\n",
      "  -2.34827529  -5.42510952  -4.20831139  -0.15233046   0.84468958\n",
      "  -6.34965259  -3.9466997   -4.31297456  -1.26376699  -1.09290275\n",
      "  -0.239875     0.05097047  -1.21319562  -0.05876698  -2.99972235\n",
      "  -6.46671273  -4.90016956  -2.8704023   -2.14371475  -4.26646238\n",
      "  -4.71919012  -4.83113408  -2.86764202  -0.66786551  -2.97534165\n",
      "  -0.0563261   -4.4197624   -7.94858002  -3.37386678  -2.99053262\n",
      "  -3.98355505  -3.37251686  -3.24545967  -2.36382972  -2.83127092\n",
      "   0.1930023   -1.3662342   -0.17597069  -3.68393447  -1.99015424\n",
      "  -2.90249886  -2.60693089  -5.17293374  -2.4141719   -2.66659857\n",
      "  -5.45927192  -0.37748982  -3.70487604  -6.70887634  -3.04510944\n",
      "  -3.56866752  -4.48888584  -3.77679874  -4.2012488   -3.43037255\n",
      "  -3.72930658  -4.04347302  -3.55739811  -2.20044297  -4.46739625\n",
      "   0.1838647   -2.23446242  -7.53611387  -5.13977137  -4.13612085\n",
      "  -1.35647645  -1.61594932  -5.2377149   -3.8443401   -1.90556175\n",
      "  -0.47653415  -2.50713227  -7.73234172  -1.29481608  -2.78821448\n",
      "  -3.10741001  -4.41768975  -0.26805296  -4.45059849   0.38281033\n",
      "  -0.93979049  -3.30766066  -3.97467466  -3.0572305    0.35676817\n",
      "  -0.58562115  -1.961258    -3.26262666  -3.00382572  -4.16555201\n",
      "  -4.73200793  -4.30501466  -2.01256861  -2.05120581   0.45529494\n",
      "  -2.21682829  -5.50356679  -3.17626534  -0.33436057  -3.29057964\n",
      "  -0.11236146  -3.79526749  -3.34054632  -2.99827736  -0.69636208\n",
      "  -0.3103957   -1.6867454   -1.45606197  -0.55910143  -1.05213799\n",
      "  -3.056666    -3.70401894  -0.65136292  -4.46411954  -3.91067609\n",
      "  -4.09244396  -4.46234665  -3.13918014  -3.17907756  -3.6026134\n",
      "  -3.11899722  -0.93507623  -4.40247244  -2.73302868  -1.76851449\n",
      "  -1.53287805  -2.28343514  -2.6952392   -3.17646047  -3.00295757\n",
      "  -2.73317205  -2.17313568  -3.41215937  -3.84853107  -3.77821827\n",
      "  -2.32193124  -0.67339682  -3.84899315  -3.67165799  -3.34584556\n",
      "  -2.41344166  -5.37052817  -2.85570173]\n",
      "Real values are:        LogS\n",
      "0   -4.100\n",
      "1   -4.230\n",
      "2   -5.510\n",
      "3   -4.001\n",
      "4   -3.494\n",
      "..     ...\n",
      "263 -3.730\n",
      "264 -4.360\n",
      "265 -3.813\n",
      "266 -5.680\n",
      "267 -1.460\n",
      "\n",
      "[268 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "#Predict on test data\n",
    "predictions = model.predict(X_test_scaled[:])\n",
    "print(\"Predicted values are: \", predictions)\n",
    "print(\"Real values are: \", ann_ytest[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0bd07db7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -2.92077905,  -3.66828076,  -5.23971217,  -3.15884715,\n",
       "        -3.16491307,  -4.4466909 ,  -2.82857242,  -2.34594697,\n",
       "        -3.76307919,  -4.07854425,  -3.01488488,  -1.60055565,\n",
       "        -0.69878049,  -0.29589063,  -2.65751968,  -4.43457486,\n",
       "        -2.431158  ,  -2.32770961,   0.17601953,  -0.3419728 ,\n",
       "        -2.91333984,  -6.11093524,  -6.78434512,  -3.84512786,\n",
       "        -0.68547613,  -4.84210637,  -3.40458779,  -1.98405517,\n",
       "        -6.77506748,  -3.03588964,  -2.14526755,  -2.98588001,\n",
       "        -3.82050049,  -0.56556705,  -0.44415621,  -0.54328304,\n",
       "        -3.94794057,  -5.25062457,  -2.76682529,  -3.32023714,\n",
       "        -2.86338241,  -2.26325104,  -1.81823806,  -8.49030548,\n",
       "        -2.78033   ,  -3.5495207 ,  -3.34538857,  -1.94574139,\n",
       "        -2.80708241,  -3.15653275,  -4.984813  ,  -2.34482462,\n",
       "       -10.9845985 ,  -0.5837452 ,  -3.35496628,   0.08622565,\n",
       "         0.7298612 ,  -4.85439484,  -8.08068238,  -4.60447619,\n",
       "        -0.19439875,  -3.61543612,  -1.48922091,  -4.94442465,\n",
       "         0.11840123,  -7.368361  ,  -3.03242156,  -0.57564734,\n",
       "        -5.57898177,  -0.79874906,  -5.66097939,  -6.61929693,\n",
       "        -8.02293156,  -4.21743126,  -2.99605131,  -3.34561194,\n",
       "        -4.84470083,  -0.46445673,  -8.2326232 ,  -0.86509946,\n",
       "         0.66088685,  -5.24553238,  -0.37421031,  -2.86767792,\n",
       "         0.2199205 ,  -0.30627747,  -3.21097851,  -5.10771835,\n",
       "        -0.28119641,  -0.45568934,  -2.65404778,  -4.56676388,\n",
       "        -1.09383145,  -4.88079501,  -4.68075394,  -2.96800753,\n",
       "        -7.25880924,  -0.71678417,  -4.92114558,  -2.81097271,\n",
       "        -5.09125155,  -4.93584229,  -0.49807765,   0.42299443,\n",
       "         0.39986632,  -2.01995154,  -4.891774  ,  -2.87191854,\n",
       "        -2.13839608,   0.04206339,  -5.28284609,  -0.16438199,\n",
       "        -1.34703566,  -4.00336136,  -1.82360215,  -0.1947875 ,\n",
       "        -1.62744008,  -4.06670188,  -5.37374103,   0.01116125,\n",
       "        -5.61793441,  -3.80204076,  -3.87866134,  -1.20150398,\n",
       "        -2.62942785,  -2.34827529,  -5.42510952,  -4.20831139,\n",
       "        -0.15233046,   0.84468958,  -6.34965259,  -3.9466997 ,\n",
       "        -4.31297456,  -1.26376699,  -1.09290275,  -0.239875  ,\n",
       "         0.05097047,  -1.21319562,  -0.05876698,  -2.99972235,\n",
       "        -6.46671273,  -4.90016956,  -2.8704023 ,  -2.14371475,\n",
       "        -4.26646238,  -4.71919012,  -4.83113408,  -2.86764202,\n",
       "        -0.66786551,  -2.97534165,  -0.0563261 ,  -4.4197624 ,\n",
       "        -7.94858002,  -3.37386678,  -2.99053262,  -3.98355505,\n",
       "        -3.37251686,  -3.24545967,  -2.36382972,  -2.83127092,\n",
       "         0.1930023 ,  -1.3662342 ,  -0.17597069,  -3.68393447,\n",
       "        -1.99015424,  -2.90249886,  -2.60693089,  -5.17293374,\n",
       "        -2.4141719 ,  -2.66659857,  -5.45927192,  -0.37748982,\n",
       "        -3.70487604,  -6.70887634,  -3.04510944,  -3.56866752,\n",
       "        -4.48888584,  -3.77679874,  -4.2012488 ,  -3.43037255,\n",
       "        -3.72930658,  -4.04347302,  -3.55739811,  -2.20044297,\n",
       "        -4.46739625,   0.1838647 ,  -2.23446242,  -7.53611387,\n",
       "        -5.13977137,  -4.13612085,  -1.35647645,  -1.61594932,\n",
       "        -5.2377149 ,  -3.8443401 ,  -1.90556175,  -0.47653415,\n",
       "        -2.50713227,  -7.73234172,  -1.29481608,  -2.78821448,\n",
       "        -3.10741001,  -4.41768975,  -0.26805296,  -4.45059849,\n",
       "         0.38281033,  -0.93979049,  -3.30766066,  -3.97467466,\n",
       "        -3.0572305 ,   0.35676817,  -0.58562115,  -1.961258  ,\n",
       "        -3.26262666,  -3.00382572,  -4.16555201,  -4.73200793,\n",
       "        -4.30501466,  -2.01256861,  -2.05120581,   0.45529494,\n",
       "        -2.21682829,  -5.50356679,  -3.17626534,  -0.33436057,\n",
       "        -3.29057964,  -0.11236146,  -3.79526749,  -3.34054632,\n",
       "        -2.99827736,  -0.69636208,  -0.3103957 ,  -1.6867454 ,\n",
       "        -1.45606197,  -0.55910143,  -1.05213799,  -3.056666  ,\n",
       "        -3.70401894,  -0.65136292,  -4.46411954,  -3.91067609,\n",
       "        -4.09244396,  -4.46234665,  -3.13918014,  -3.17907756,\n",
       "        -3.6026134 ,  -3.11899722,  -0.93507623,  -4.40247244,\n",
       "        -2.73302868,  -1.76851449,  -1.53287805,  -2.28343514,\n",
       "        -2.6952392 ,  -3.17646047,  -3.00295757,  -2.73317205,\n",
       "        -2.17313568,  -3.41215937,  -3.84853107,  -3.77821827,\n",
       "        -2.32193124,  -0.67339682,  -3.84899315,  -3.67165799,\n",
       "        -3.34584556,  -2.41344166,  -5.37052817,  -2.85570173])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "14795576",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_prediction = pd.DataFrame(predictions, columns=['LogS']).to_csv('E:/Leeds University/Dissertation/ann_prediction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "340d1a30",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RandomForestRegressor' object has no attribute 'evaluate'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-de067aa48c70>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Comparison with other models..\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#Neural network - from the current code\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmse_neural\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmae_neural\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_scaled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mann_ytest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Root Mean squared error from neural net: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmse_neural\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Mean absolute error from neural net: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmae_neural\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'RandomForestRegressor' object has no attribute 'evaluate'"
     ]
    }
   ],
   "source": [
    "#Comparison with other models..\n",
    "#Neural network - from the current code\n",
    "mse_neural, mae_neural = model.evaluate(X_test_scaled, ann_ytest)\n",
    "print('Root Mean squared error from neural net: ', sqrt(mse_neural))\n",
    "print('Mean absolute error from neural net: ', mae_neural)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49573d12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ae466c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error from linear regression:  1.2973471996671648\n",
      "Mean absolute error from linear regression:  0.8678918853223664\n"
     ]
    }
   ],
   "source": [
    "######################################################################\n",
    "#Linear regression\n",
    "from sklearn import linear_model\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "### Linear regression\n",
    "lr_model = linear_model.LinearRegression()\n",
    "lr_model.fit(X_train_scaled, ann_ytrain)\n",
    "y_pred_lr = lr_model.predict(X_test_scaled)\n",
    "mse_lr = mean_squared_error(ann_ytest, y_pred_lr)\n",
    "mae_lr = mean_absolute_error(ann_ytest, y_pred_lr)\n",
    "print('Mean squared error from linear regression: ', mse_lr)\n",
    "print('Mean absolute error from linear regression: ', mae_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6dfd6264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error using decision tree:  1.6063857694574628\n",
      "Mean absolute error using decision tree:  0.9500794552238807\n"
     ]
    }
   ],
   "source": [
    "############################################################\n",
    "### Decision tree\n",
    "tree = DecisionTreeRegressor()\n",
    "tree.fit(X_train_scaled, ann_ytrain)\n",
    "y_pred_tree = tree.predict(X_test_scaled)\n",
    "mse_dt = mean_squared_error(ann_ytest, y_pred_tree)\n",
    "mae_dt = mean_absolute_error(ann_ytest, y_pred_tree)\n",
    "print('Mean squared error using decision tree: ', mse_dt)\n",
    "print('Mean absolute error using decision tree: ', mae_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bb1d5f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-35-0acdf5c6bcfb>:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  model.fit(X_train_scaled, ann_ytrain)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error using Random Forest:  0.7786696068137872\n",
      "Mean absolute error Using Random Forest:  0.6948609628871277\n"
     ]
    }
   ],
   "source": [
    "##############################################\n",
    "#Random forest.\n",
    "#Increase number of tress and see the effect\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model = RandomForestRegressor(n_estimators = 800, random_state=30)\n",
    "model.fit(X_train_scaled, ann_ytrain)\n",
    "\n",
    "y_pred_RF = model.predict(X_test_scaled)\n",
    "\n",
    "mse_RF = mean_squared_error(ann_ytest, y_pred_RF)\n",
    "mae_RF = mean_absolute_error(ann_ytest, y_pred_RF)\n",
    "print('Mean squared error using Random Forest: ', mse_RF)\n",
    "print('Mean absolute error Using Random Forest: ', mae_RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "38c22325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "volume         0.394062\n",
      "Most_neg       0.205314\n",
      "MW             0.077157\n",
      "SASA           0.060350\n",
      "Most_pos       0.055639\n",
      "Het_charges    0.042508\n",
      "G_sol          0.029816\n",
      "C_charges      0.029388\n",
      "O_charges      0.029048\n",
      "Lsolu_Hsolv    0.026980\n",
      "sol_dip        0.022317\n",
      "Lsolv_Hsolu    0.015897\n",
      "DeltaG_sol     0.011524\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Feature ranking...\n",
    "import pandas as pd\n",
    "feature_list = list(X.columns)\n",
    "feature_imp = pd.Series(model.feature_importances_, index=feature_list).sort_values(ascending=False)\n",
    "print(feature_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a24676d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
