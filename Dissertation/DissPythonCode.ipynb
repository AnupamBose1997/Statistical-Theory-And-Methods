{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5e84cfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "64ee1417",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PATH\"] += os.pathsep + 'C:/Users/Acer/anaconda3/Library/bin/graphviz/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5aef0cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_csv(\"E:/Leeds University/Dissertation/desdata.csv\", delim_whitespace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "62c16b20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Compound', 'G_sol', 'DeltaG_sol', 'volume', 'sol_dip', 'O_charges',\n",
       "       'C_charges', 'Most_neg', 'Most_pos', 'Het_charges', 'MW', 'SASA',\n",
       "       'LogS', 'Lsolu_Hsolv', 'Lsolv_Hsolu'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4959e52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[:, df.columns != 'Compound']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c050b23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split into features and target (Price)\n",
    "X = df.drop('LogS', axis = 1)\n",
    "y = df['LogS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "cd607289",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "bcaced37",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_xtrain = read_csv(\"E:/Leeds University/Dissertation/ann_xtrain.csv\", delim_whitespace=False)\n",
    "ann_xtest = read_csv(\"E:/Leeds University/Dissertation/ann_xtest.csv\", delim_whitespace=False)\n",
    "ann_ytrain = read_csv(\"E:/Leeds University/Dissertation/ann_ytrain.csv\", delim_whitespace=False)\n",
    "ann_ytest = read_csv(\"E:/Leeds University/Dissertation/ann_ytest.csv\", delim_whitespace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4022e90c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scale data, otherwise model will fail.\n",
    "#Standardize features by removing the mean and scaling to unit variance\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()\n",
    "scaler.fit(ann_xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "10970afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = scaler.transform(ann_xtrain)\n",
    "X_test_scaled = scaler.transform(ann_xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "86f65e70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LogS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-4.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-4.230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-5.510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-4.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-3.494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>-3.730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>-4.360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>-3.813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>-5.680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>-1.460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>268 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      LogS\n",
       "0   -4.100\n",
       "1   -4.230\n",
       "2   -5.510\n",
       "3   -4.001\n",
       "4   -3.494\n",
       "..     ...\n",
       "263 -3.730\n",
       "264 -4.360\n",
       "265 -3.813\n",
       "266 -5.680\n",
       "267 -1.460\n",
       "\n",
       "[268 rows x 1 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann_ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "24b72a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (None, 128)               1792      \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,113\n",
      "Trainable params: 10,113\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# define the model\n",
    "#Experiment with deeper and wider networks\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=13, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "#Output layer\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mae'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1df7ef69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ann_visualizer.visualize import ann_viz;\n",
    "\n",
    "ann_viz(model, title=\"Neural Network Plot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "206609d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "16/16 [==============================] - 9s 37ms/step - loss: 11.8371 - mae: 2.7675 - val_loss: 9.0174 - val_mae: 2.2661\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 6.0318 - mae: 1.9651 - val_loss: 4.3532 - val_mae: 1.6745\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.8667 - mae: 1.3736 - val_loss: 2.1851 - val_mae: 1.1366\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.9688 - mae: 1.0848 - val_loss: 1.9319 - val_mae: 1.0267\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.7259 - mae: 1.0035 - val_loss: 1.7631 - val_mae: 1.0051\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.5409 - mae: 0.9379 - val_loss: 1.6572 - val_mae: 0.9731\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.4433 - mae: 0.9019 - val_loss: 1.6243 - val_mae: 0.9618\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.3657 - mae: 0.8736 - val_loss: 1.5691 - val_mae: 0.9496\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.2815 - mae: 0.8438 - val_loss: 1.5375 - val_mae: 0.9347\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.2258 - mae: 0.8169 - val_loss: 1.5008 - val_mae: 0.9248\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.1779 - mae: 0.8008 - val_loss: 1.4851 - val_mae: 0.9168\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.1322 - mae: 0.7839 - val_loss: 1.4615 - val_mae: 0.9099\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.1079 - mae: 0.7793 - val_loss: 1.4606 - val_mae: 0.9088\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.0800 - mae: 0.7654 - val_loss: 1.4354 - val_mae: 0.9070\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.0533 - mae: 0.7536 - val_loss: 1.3951 - val_mae: 0.8885\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.0115 - mae: 0.7423 - val_loss: 1.4262 - val_mae: 0.8994\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.9877 - mae: 0.7258 - val_loss: 1.4098 - val_mae: 0.8878\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.9614 - mae: 0.7238 - val_loss: 1.3511 - val_mae: 0.8696\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.9378 - mae: 0.7164 - val_loss: 1.3488 - val_mae: 0.8658\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.9076 - mae: 0.6927 - val_loss: 1.3704 - val_mae: 0.8859\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.8970 - mae: 0.6985 - val_loss: 1.3366 - val_mae: 0.8634\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.8705 - mae: 0.6888 - val_loss: 1.3170 - val_mae: 0.8574\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.8629 - mae: 0.6734 - val_loss: 1.3637 - val_mae: 0.8634\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.8258 - mae: 0.6629 - val_loss: 1.2942 - val_mae: 0.8449\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.8127 - mae: 0.6551 - val_loss: 1.2878 - val_mae: 0.8420\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.8008 - mae: 0.6533 - val_loss: 1.3022 - val_mae: 0.8475\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7821 - mae: 0.6477 - val_loss: 1.2635 - val_mae: 0.8305\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7466 - mae: 0.6274 - val_loss: 1.2827 - val_mae: 0.8451\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7330 - mae: 0.6230 - val_loss: 1.2951 - val_mae: 0.8504\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7191 - mae: 0.6233 - val_loss: 1.2509 - val_mae: 0.8236\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7343 - mae: 0.6214 - val_loss: 1.3473 - val_mae: 0.8570\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7398 - mae: 0.6344 - val_loss: 1.2731 - val_mae: 0.8405\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6932 - mae: 0.6049 - val_loss: 1.2450 - val_mae: 0.8195\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6679 - mae: 0.5900 - val_loss: 1.2587 - val_mae: 0.8314\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6522 - mae: 0.5835 - val_loss: 1.2489 - val_mae: 0.8217\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6399 - mae: 0.5890 - val_loss: 1.2529 - val_mae: 0.8237\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6268 - mae: 0.5769 - val_loss: 1.2370 - val_mae: 0.8155\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6085 - mae: 0.5669 - val_loss: 1.2206 - val_mae: 0.8200\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6158 - mae: 0.5686 - val_loss: 1.2916 - val_mae: 0.8407\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5815 - mae: 0.5527 - val_loss: 1.2467 - val_mae: 0.8321\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5915 - mae: 0.5588 - val_loss: 1.2247 - val_mae: 0.8099\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5637 - mae: 0.5475 - val_loss: 1.2161 - val_mae: 0.8087\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5652 - mae: 0.5430 - val_loss: 1.2259 - val_mae: 0.8080\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5517 - mae: 0.5477 - val_loss: 1.2217 - val_mae: 0.8176\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5563 - mae: 0.5476 - val_loss: 1.2288 - val_mae: 0.8101\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5355 - mae: 0.5286 - val_loss: 1.2437 - val_mae: 0.8173\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5243 - mae: 0.5253 - val_loss: 1.1811 - val_mae: 0.8060\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5183 - mae: 0.5250 - val_loss: 1.2316 - val_mae: 0.8273\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4972 - mae: 0.5153 - val_loss: 1.1929 - val_mae: 0.7995\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.4860 - mae: 0.5070 - val_loss: 1.1863 - val_mae: 0.8040\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.4821 - mae: 0.5040 - val_loss: 1.2017 - val_mae: 0.7992\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.4771 - mae: 0.4914 - val_loss: 1.1985 - val_mae: 0.8070\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.4760 - mae: 0.4952 - val_loss: 1.1986 - val_mae: 0.8075\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4848 - mae: 0.5083 - val_loss: 1.1991 - val_mae: 0.8090\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.4649 - mae: 0.5035 - val_loss: 1.1871 - val_mae: 0.8068\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.4540 - mae: 0.4971 - val_loss: 1.1461 - val_mae: 0.7916\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.4571 - mae: 0.4850 - val_loss: 1.2593 - val_mae: 0.8238\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4540 - mae: 0.4945 - val_loss: 1.1858 - val_mae: 0.7968\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.4314 - mae: 0.4829 - val_loss: 1.2110 - val_mae: 0.8119\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.4219 - mae: 0.4723 - val_loss: 1.2073 - val_mae: 0.8121\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4225 - mae: 0.4838 - val_loss: 1.1513 - val_mae: 0.7874\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.4166 - mae: 0.4744 - val_loss: 1.1851 - val_mae: 0.8031\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 3ms/step - loss: 0.4235 - mae: 0.4790 - val_loss: 1.1838 - val_mae: 0.8051\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.4214 - mae: 0.4737 - val_loss: 1.2175 - val_mae: 0.8036\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.4035 - mae: 0.4787 - val_loss: 1.1479 - val_mae: 0.7939\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3913 - mae: 0.4607 - val_loss: 1.1373 - val_mae: 0.7856\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3875 - mae: 0.4586 - val_loss: 1.1487 - val_mae: 0.7875\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3804 - mae: 0.4502 - val_loss: 1.2080 - val_mae: 0.8089\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3651 - mae: 0.4451 - val_loss: 1.1392 - val_mae: 0.7855\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3722 - mae: 0.4521 - val_loss: 1.1765 - val_mae: 0.7927\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3632 - mae: 0.4506 - val_loss: 1.1710 - val_mae: 0.7881\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3577 - mae: 0.4411 - val_loss: 1.1310 - val_mae: 0.7888\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3631 - mae: 0.4487 - val_loss: 1.1175 - val_mae: 0.7804\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3694 - mae: 0.4569 - val_loss: 1.1935 - val_mae: 0.8076\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3488 - mae: 0.4352 - val_loss: 1.1328 - val_mae: 0.7819\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3374 - mae: 0.4341 - val_loss: 1.1319 - val_mae: 0.7900\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3426 - mae: 0.4328 - val_loss: 1.1626 - val_mae: 0.7862\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3407 - mae: 0.4385 - val_loss: 1.1783 - val_mae: 0.8064\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3233 - mae: 0.4309 - val_loss: 1.1173 - val_mae: 0.7806\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3181 - mae: 0.4214 - val_loss: 1.1360 - val_mae: 0.7761\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3145 - mae: 0.4156 - val_loss: 1.1742 - val_mae: 0.8073\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3010 - mae: 0.4089 - val_loss: 1.1680 - val_mae: 0.7922\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2895 - mae: 0.3921 - val_loss: 1.1731 - val_mae: 0.7851\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2995 - mae: 0.4104 - val_loss: 1.1502 - val_mae: 0.7939\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2861 - mae: 0.3994 - val_loss: 1.1143 - val_mae: 0.7692\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2853 - mae: 0.4003 - val_loss: 1.2140 - val_mae: 0.8059\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2942 - mae: 0.4039 - val_loss: 1.1351 - val_mae: 0.7794\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2744 - mae: 0.3906 - val_loss: 1.1531 - val_mae: 0.7868\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2759 - mae: 0.3937 - val_loss: 1.1981 - val_mae: 0.7970\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2809 - mae: 0.3947 - val_loss: 1.1526 - val_mae: 0.7817\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2687 - mae: 0.3857 - val_loss: 1.1988 - val_mae: 0.7896\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2708 - mae: 0.3903 - val_loss: 1.1024 - val_mae: 0.7633\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2588 - mae: 0.3775 - val_loss: 1.1305 - val_mae: 0.7676\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2584 - mae: 0.3743 - val_loss: 1.1786 - val_mae: 0.8005\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2437 - mae: 0.3665 - val_loss: 1.1551 - val_mae: 0.7744\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2584 - mae: 0.3762 - val_loss: 1.1535 - val_mae: 0.7785\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2676 - mae: 0.3796 - val_loss: 1.1364 - val_mae: 0.7816\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2373 - mae: 0.3620 - val_loss: 1.1423 - val_mae: 0.7676\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2482 - mae: 0.3777 - val_loss: 1.1602 - val_mae: 0.7798\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2477 - mae: 0.3671 - val_loss: 1.1404 - val_mae: 0.7751\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_scaled, ann_ytrain, validation_split=0.2, epochs =100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "5d11c4fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "#plot the training and validation accuracy and loss at each epoch\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'g', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "resolution_value=1200\n",
    "plt.savefig('E:/Leeds University/Dissertation/ann_model.png',format='png',dpi=resolution_value)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3016a70d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted values are:  [ -2.92077905  -3.66828076  -5.23971217  -3.15884715  -3.16491307\n",
      "  -4.4466909   -2.82857242  -2.34594697  -3.76307919  -4.07854425\n",
      "  -3.01488488  -1.60055565  -0.69878049  -0.29589063  -2.65751968\n",
      "  -4.43457486  -2.431158    -2.32770961   0.17601953  -0.3419728\n",
      "  -2.91333984  -6.11093524  -6.78434512  -3.84512786  -0.68547613\n",
      "  -4.84210637  -3.40458779  -1.98405517  -6.77506748  -3.03588964\n",
      "  -2.14526755  -2.98588001  -3.82050049  -0.56556705  -0.44415621\n",
      "  -0.54328304  -3.94794057  -5.25062457  -2.76682529  -3.32023714\n",
      "  -2.86338241  -2.26325104  -1.81823806  -8.49030548  -2.78033\n",
      "  -3.5495207   -3.34538857  -1.94574139  -2.80708241  -3.15653275\n",
      "  -4.984813    -2.34482462 -10.9845985   -0.5837452   -3.35496628\n",
      "   0.08622565   0.7298612   -4.85439484  -8.08068238  -4.60447619\n",
      "  -0.19439875  -3.61543612  -1.48922091  -4.94442465   0.11840123\n",
      "  -7.368361    -3.03242156  -0.57564734  -5.57898177  -0.79874906\n",
      "  -5.66097939  -6.61929693  -8.02293156  -4.21743126  -2.99605131\n",
      "  -3.34561194  -4.84470083  -0.46445673  -8.2326232   -0.86509946\n",
      "   0.66088685  -5.24553238  -0.37421031  -2.86767792   0.2199205\n",
      "  -0.30627747  -3.21097851  -5.10771835  -0.28119641  -0.45568934\n",
      "  -2.65404778  -4.56676388  -1.09383145  -4.88079501  -4.68075394\n",
      "  -2.96800753  -7.25880924  -0.71678417  -4.92114558  -2.81097271\n",
      "  -5.09125155  -4.93584229  -0.49807765   0.42299443   0.39986632\n",
      "  -2.01995154  -4.891774    -2.87191854  -2.13839608   0.04206339\n",
      "  -5.28284609  -0.16438199  -1.34703566  -4.00336136  -1.82360215\n",
      "  -0.1947875   -1.62744008  -4.06670188  -5.37374103   0.01116125\n",
      "  -5.61793441  -3.80204076  -3.87866134  -1.20150398  -2.62942785\n",
      "  -2.34827529  -5.42510952  -4.20831139  -0.15233046   0.84468958\n",
      "  -6.34965259  -3.9466997   -4.31297456  -1.26376699  -1.09290275\n",
      "  -0.239875     0.05097047  -1.21319562  -0.05876698  -2.99972235\n",
      "  -6.46671273  -4.90016956  -2.8704023   -2.14371475  -4.26646238\n",
      "  -4.71919012  -4.83113408  -2.86764202  -0.66786551  -2.97534165\n",
      "  -0.0563261   -4.4197624   -7.94858002  -3.37386678  -2.99053262\n",
      "  -3.98355505  -3.37251686  -3.24545967  -2.36382972  -2.83127092\n",
      "   0.1930023   -1.3662342   -0.17597069  -3.68393447  -1.99015424\n",
      "  -2.90249886  -2.60693089  -5.17293374  -2.4141719   -2.66659857\n",
      "  -5.45927192  -0.37748982  -3.70487604  -6.70887634  -3.04510944\n",
      "  -3.56866752  -4.48888584  -3.77679874  -4.2012488   -3.43037255\n",
      "  -3.72930658  -4.04347302  -3.55739811  -2.20044297  -4.46739625\n",
      "   0.1838647   -2.23446242  -7.53611387  -5.13977137  -4.13612085\n",
      "  -1.35647645  -1.61594932  -5.2377149   -3.8443401   -1.90556175\n",
      "  -0.47653415  -2.50713227  -7.73234172  -1.29481608  -2.78821448\n",
      "  -3.10741001  -4.41768975  -0.26805296  -4.45059849   0.38281033\n",
      "  -0.93979049  -3.30766066  -3.97467466  -3.0572305    0.35676817\n",
      "  -0.58562115  -1.961258    -3.26262666  -3.00382572  -4.16555201\n",
      "  -4.73200793  -4.30501466  -2.01256861  -2.05120581   0.45529494\n",
      "  -2.21682829  -5.50356679  -3.17626534  -0.33436057  -3.29057964\n",
      "  -0.11236146  -3.79526749  -3.34054632  -2.99827736  -0.69636208\n",
      "  -0.3103957   -1.6867454   -1.45606197  -0.55910143  -1.05213799\n",
      "  -3.056666    -3.70401894  -0.65136292  -4.46411954  -3.91067609\n",
      "  -4.09244396  -4.46234665  -3.13918014  -3.17907756  -3.6026134\n",
      "  -3.11899722  -0.93507623  -4.40247244  -2.73302868  -1.76851449\n",
      "  -1.53287805  -2.28343514  -2.6952392   -3.17646047  -3.00295757\n",
      "  -2.73317205  -2.17313568  -3.41215937  -3.84853107  -3.77821827\n",
      "  -2.32193124  -0.67339682  -3.84899315  -3.67165799  -3.34584556\n",
      "  -2.41344166  -5.37052817  -2.85570173]\n",
      "Real values are:        LogS\n",
      "0   -4.100\n",
      "1   -4.230\n",
      "2   -5.510\n",
      "3   -4.001\n",
      "4   -3.494\n",
      "..     ...\n",
      "263 -3.730\n",
      "264 -4.360\n",
      "265 -3.813\n",
      "266 -5.680\n",
      "267 -1.460\n",
      "\n",
      "[268 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "#Predict on test data\n",
    "predictions = model.predict(X_test_scaled[:])\n",
    "print(\"Predicted values are: \", predictions)\n",
    "print(\"Real values are: \", ann_ytest[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3d7da00d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -2.92077905,  -3.66828076,  -5.23971217,  -3.15884715,\n",
       "        -3.16491307,  -4.4466909 ,  -2.82857242,  -2.34594697,\n",
       "        -3.76307919,  -4.07854425,  -3.01488488,  -1.60055565,\n",
       "        -0.69878049,  -0.29589063,  -2.65751968,  -4.43457486,\n",
       "        -2.431158  ,  -2.32770961,   0.17601953,  -0.3419728 ,\n",
       "        -2.91333984,  -6.11093524,  -6.78434512,  -3.84512786,\n",
       "        -0.68547613,  -4.84210637,  -3.40458779,  -1.98405517,\n",
       "        -6.77506748,  -3.03588964,  -2.14526755,  -2.98588001,\n",
       "        -3.82050049,  -0.56556705,  -0.44415621,  -0.54328304,\n",
       "        -3.94794057,  -5.25062457,  -2.76682529,  -3.32023714,\n",
       "        -2.86338241,  -2.26325104,  -1.81823806,  -8.49030548,\n",
       "        -2.78033   ,  -3.5495207 ,  -3.34538857,  -1.94574139,\n",
       "        -2.80708241,  -3.15653275,  -4.984813  ,  -2.34482462,\n",
       "       -10.9845985 ,  -0.5837452 ,  -3.35496628,   0.08622565,\n",
       "         0.7298612 ,  -4.85439484,  -8.08068238,  -4.60447619,\n",
       "        -0.19439875,  -3.61543612,  -1.48922091,  -4.94442465,\n",
       "         0.11840123,  -7.368361  ,  -3.03242156,  -0.57564734,\n",
       "        -5.57898177,  -0.79874906,  -5.66097939,  -6.61929693,\n",
       "        -8.02293156,  -4.21743126,  -2.99605131,  -3.34561194,\n",
       "        -4.84470083,  -0.46445673,  -8.2326232 ,  -0.86509946,\n",
       "         0.66088685,  -5.24553238,  -0.37421031,  -2.86767792,\n",
       "         0.2199205 ,  -0.30627747,  -3.21097851,  -5.10771835,\n",
       "        -0.28119641,  -0.45568934,  -2.65404778,  -4.56676388,\n",
       "        -1.09383145,  -4.88079501,  -4.68075394,  -2.96800753,\n",
       "        -7.25880924,  -0.71678417,  -4.92114558,  -2.81097271,\n",
       "        -5.09125155,  -4.93584229,  -0.49807765,   0.42299443,\n",
       "         0.39986632,  -2.01995154,  -4.891774  ,  -2.87191854,\n",
       "        -2.13839608,   0.04206339,  -5.28284609,  -0.16438199,\n",
       "        -1.34703566,  -4.00336136,  -1.82360215,  -0.1947875 ,\n",
       "        -1.62744008,  -4.06670188,  -5.37374103,   0.01116125,\n",
       "        -5.61793441,  -3.80204076,  -3.87866134,  -1.20150398,\n",
       "        -2.62942785,  -2.34827529,  -5.42510952,  -4.20831139,\n",
       "        -0.15233046,   0.84468958,  -6.34965259,  -3.9466997 ,\n",
       "        -4.31297456,  -1.26376699,  -1.09290275,  -0.239875  ,\n",
       "         0.05097047,  -1.21319562,  -0.05876698,  -2.99972235,\n",
       "        -6.46671273,  -4.90016956,  -2.8704023 ,  -2.14371475,\n",
       "        -4.26646238,  -4.71919012,  -4.83113408,  -2.86764202,\n",
       "        -0.66786551,  -2.97534165,  -0.0563261 ,  -4.4197624 ,\n",
       "        -7.94858002,  -3.37386678,  -2.99053262,  -3.98355505,\n",
       "        -3.37251686,  -3.24545967,  -2.36382972,  -2.83127092,\n",
       "         0.1930023 ,  -1.3662342 ,  -0.17597069,  -3.68393447,\n",
       "        -1.99015424,  -2.90249886,  -2.60693089,  -5.17293374,\n",
       "        -2.4141719 ,  -2.66659857,  -5.45927192,  -0.37748982,\n",
       "        -3.70487604,  -6.70887634,  -3.04510944,  -3.56866752,\n",
       "        -4.48888584,  -3.77679874,  -4.2012488 ,  -3.43037255,\n",
       "        -3.72930658,  -4.04347302,  -3.55739811,  -2.20044297,\n",
       "        -4.46739625,   0.1838647 ,  -2.23446242,  -7.53611387,\n",
       "        -5.13977137,  -4.13612085,  -1.35647645,  -1.61594932,\n",
       "        -5.2377149 ,  -3.8443401 ,  -1.90556175,  -0.47653415,\n",
       "        -2.50713227,  -7.73234172,  -1.29481608,  -2.78821448,\n",
       "        -3.10741001,  -4.41768975,  -0.26805296,  -4.45059849,\n",
       "         0.38281033,  -0.93979049,  -3.30766066,  -3.97467466,\n",
       "        -3.0572305 ,   0.35676817,  -0.58562115,  -1.961258  ,\n",
       "        -3.26262666,  -3.00382572,  -4.16555201,  -4.73200793,\n",
       "        -4.30501466,  -2.01256861,  -2.05120581,   0.45529494,\n",
       "        -2.21682829,  -5.50356679,  -3.17626534,  -0.33436057,\n",
       "        -3.29057964,  -0.11236146,  -3.79526749,  -3.34054632,\n",
       "        -2.99827736,  -0.69636208,  -0.3103957 ,  -1.6867454 ,\n",
       "        -1.45606197,  -0.55910143,  -1.05213799,  -3.056666  ,\n",
       "        -3.70401894,  -0.65136292,  -4.46411954,  -3.91067609,\n",
       "        -4.09244396,  -4.46234665,  -3.13918014,  -3.17907756,\n",
       "        -3.6026134 ,  -3.11899722,  -0.93507623,  -4.40247244,\n",
       "        -2.73302868,  -1.76851449,  -1.53287805,  -2.28343514,\n",
       "        -2.6952392 ,  -3.17646047,  -3.00295757,  -2.73317205,\n",
       "        -2.17313568,  -3.41215937,  -3.84853107,  -3.77821827,\n",
       "        -2.32193124,  -0.67339682,  -3.84899315,  -3.67165799,\n",
       "        -3.34584556,  -2.41344166,  -5.37052817,  -2.85570173])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b836b8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_prediction = pd.DataFrame(predictions, columns=['LogS']).to_csv('E:/Leeds University/Dissertation/ann_prediction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "340d1a30",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RandomForestRegressor' object has no attribute 'evaluate'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-59e942264a05>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Comparison with other models..\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#Neural network - from the current code\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmse_neural\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmae_neural\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_scaled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mann_ytest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Root Mean squared error from neural net: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmse_neural\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Mean absolute error from neural net: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmae_neural\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'RandomForestRegressor' object has no attribute 'evaluate'"
     ]
    }
   ],
   "source": [
    "#Comparison with other models..\n",
    "#Neural network - from the current code\n",
    "mse_neural, mae_neural = model.evaluate(X_test_scaled, ann_ytest)\n",
    "print('Root Mean squared error from neural net: ', mse_neural)\n",
    "print('Mean absolute error from neural net: ', mae_neural)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fe70f430",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1a98c63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ae466c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error from linear regression:  1.2973471996671648\n",
      "Mean absolute error from linear regression:  0.8678918853223664\n"
     ]
    }
   ],
   "source": [
    "######################################################################\n",
    "#Linear regression\n",
    "from sklearn import linear_model\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "### Linear regression\n",
    "lr_model = linear_model.LinearRegression()\n",
    "lr_model.fit(X_train_scaled, ann_ytrain)\n",
    "y_pred_lr = lr_model.predict(X_test_scaled)\n",
    "mse_lr = mean_squared_error(ann_ytest, y_pred_lr)\n",
    "mae_lr = mean_absolute_error(ann_ytest, y_pred_lr)\n",
    "print('Mean squared error from linear regression: ', mse_lr)\n",
    "print('Mean absolute error from linear regression: ', mae_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6dfd6264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error using decision tree:  1.6063857694574628\n",
      "Mean absolute error using decision tree:  0.9500794552238807\n"
     ]
    }
   ],
   "source": [
    "############################################################\n",
    "### Decision tree\n",
    "tree = DecisionTreeRegressor()\n",
    "tree.fit(X_train_scaled, ann_ytrain)\n",
    "y_pred_tree = tree.predict(X_test_scaled)\n",
    "mse_dt = mean_squared_error(ann_ytest, y_pred_tree)\n",
    "mae_dt = mean_absolute_error(ann_ytest, y_pred_tree)\n",
    "print('Mean squared error using decision tree: ', mse_dt)\n",
    "print('Mean absolute error using decision tree: ', mae_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bb1d5f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-35-0acdf5c6bcfb>:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  model.fit(X_train_scaled, ann_ytrain)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error using Random Forest:  0.7786696068137872\n",
      "Mean absolute error Using Random Forest:  0.6948609628871277\n"
     ]
    }
   ],
   "source": [
    "##############################################\n",
    "#Random forest.\n",
    "#Increase number of tress and see the effect\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model = RandomForestRegressor(n_estimators = 800, random_state=30)\n",
    "model.fit(X_train_scaled, ann_ytrain)\n",
    "\n",
    "y_pred_RF = model.predict(X_test_scaled)\n",
    "\n",
    "mse_RF = mean_squared_error(ann_ytest, y_pred_RF)\n",
    "mae_RF = mean_absolute_error(ann_ytest, y_pred_RF)\n",
    "print('Mean squared error using Random Forest: ', mse_RF)\n",
    "print('Mean absolute error Using Random Forest: ', mae_RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "38c22325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "volume         0.394062\n",
      "Most_neg       0.205314\n",
      "MW             0.077157\n",
      "SASA           0.060350\n",
      "Most_pos       0.055639\n",
      "Het_charges    0.042508\n",
      "G_sol          0.029816\n",
      "C_charges      0.029388\n",
      "O_charges      0.029048\n",
      "Lsolu_Hsolv    0.026980\n",
      "sol_dip        0.022317\n",
      "Lsolv_Hsolu    0.015897\n",
      "DeltaG_sol     0.011524\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Feature ranking...\n",
    "import pandas as pd\n",
    "feature_list = list(X.columns)\n",
    "feature_imp = pd.Series(model.feature_importances_, index=feature_list).sort_values(ascending=False)\n",
    "print(feature_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a24676d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
